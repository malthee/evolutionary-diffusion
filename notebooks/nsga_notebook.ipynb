{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Template Notebook for NSGA II Multi-Objective-Optimization exploring the Prompt Embedding space\n",
    "Notebook Version: 0.3 (06/03/2024)\n",
    "* added Google Colab support"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c0bdb332e586951"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Google Colab Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8d329337a9a6ae4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Google Colab: Execute this to install packages and setup drive\n",
    "!pip install \"evolutionary[all] @ git+https://git@github.com/malthee/evolutionary-diffusion.git\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e29d72d1cf8f831b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mount drive to save results\n",
    "from google.colab import drive\n",
    "import evolutionary_imaging.processing as ip\n",
    "drive.mount(\"/content/drive\")\n",
    "base_path = \"/content/drive/MyDrive/evolutionary/\"\n",
    "ip.RESULTS_FOLDER = base_path + ip.RESULTS_FOLDER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9823a776d3aa5811"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fce51ef77417054c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68639543cb9a264"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evolutionary.plotting import plot_fitness_statistics\n",
    "import evolutionary_imaging.processing as ip\n",
    "from diffusers.utils import logging\n",
    "from evolutionary_imaging.processing import create_animation_from_generations, create_generation_image_grid, save_images_from_generation\n",
    "import torch\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60dbb3fefb89efd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.disable_progress_bar() # Or else your output will be full of progress bars\n",
    "logging.set_verbosity_error() # Enable again if you are having problems\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To remove warning of libraries using tokenizers\n",
    "# Change the results folder for images if you want to \n",
    "# ip.RESULTS_FOLDER = 'choose_your_destination'\n",
    "\n",
    "def save_images_post_evaluation(g, a):\n",
    "    save_images_from_generation(a.population, g)\n",
    "    \n",
    "# Check torch random state, used across all libraries. Caution setting fixed seeds as it affects not only generation but also variation.\n",
    "print(torch.random.get_rng_state())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d41ebb7614cac219"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from evolutionary_prompt_embedding.image_creation import SDXLPromptEmbeddingImageCreator\n",
    "from evolutionary_prompt_embedding.variation import PooledArithmeticCrossover, PooledUniformGaussianMutator, UniformGaussianMutatorArguments\n",
    "from evolutionary.evolutionary_selectors import TournamentSelector\n",
    "from evolutionary.algorithms.nsga_ii import NSGA_II\n",
    "from evolutionary_imaging.evaluators import AestheticsImageEvaluator, CLIPScoreEvaluator, MultiCLIPIQAEvaluator, \\\n",
    "    SingleCLIPIQAEvaluator\n",
    "from evolutionary.evolution_base import MultiObjectiveEvaluator\n",
    "\n",
    "prompt = \"van gogh\"\n",
    "population_size = 5\n",
    "num_generations = 5\n",
    "batch_size = 2\n",
    "elitism = 1\n",
    "\n",
    "creator = SDXLPromptEmbeddingImageCreator(batch_size=batch_size, inference_steps=3)\n",
    "evaluator = MultiObjectiveEvaluator([\n",
    "    AestheticsImageEvaluator(), \n",
    "    CLIPScoreEvaluator(prompt=prompt),\n",
    "    MultiCLIPIQAEvaluator(metrics=('quality', 'brightness', ('good', 'bad'))),\n",
    "    SingleCLIPIQAEvaluator(metric=('testness', 'notntestness'))\n",
    "])\n",
    "crossover = PooledArithmeticCrossover(crossover_rate=0.5, crossover_rate_pooled=0.5)\n",
    "# clamp_range was evaluated with pre-testing/clamp_range/sdxl_turbo.py\n",
    "mutation_arguments = UniformGaussianMutatorArguments(mutation_rate=0.1, mutation_strength=2.5, clamp_range=(-900, 900)) \n",
    "mutation_arguments_pooled = UniformGaussianMutatorArguments(mutation_rate=0.1, mutation_strength=0.5, clamp_range=(-8, 8))\n",
    "mutator = PooledUniformGaussianMutator(mutation_arguments, mutation_arguments_pooled)\n",
    "selector = TournamentSelector(tournament_size=3)\n",
    "\n",
    "# Prepare initial arguments\n",
    "init_embed = creator.arguments_from_prompt(prompt)\n",
    "init_args = [init_embed for _ in range(population_size)]\n",
    "\n",
    "nsga = NSGA_II(\n",
    "    num_generations=num_generations,\n",
    "    population_size=population_size,\n",
    "    solution_creator=creator,\n",
    "    selector=selector,\n",
    "    crossover=crossover,\n",
    "    mutator=mutator,\n",
    "    evaluator=evaluator,\n",
    "    elitism_count=elitism,\n",
    "    initial_arguments=init_args,\n",
    "    post_evaluation_callback=lambda g, a: save_images_from_generation(a.population, g)  # TODO save only best images (in front 0) post sorting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_solution = nsga.run()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "935da12fdef0f9e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "# Show best solution\n",
    "print(best_solution.fitness)\n",
    "make_image_grid(best_solution.result.images, 1, batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "138e75cca37887ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the evolution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ec401b70d26330"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gen in range(num_generations):\n",
    "    create_generation_image_grid(gen, max_images=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "654d29c0a9adc5ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "video_loc = create_animation_from_generations(num_generations)\n",
    "print(video_loc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bc3e27bc037fc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot fitness statistics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7710ea6363c8fc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_fitness_statistics(num_generations, nsga.best_fitness, nsga.worst_fitness, nsga.avg_fitness, title=\"Aesthetics\", multi_objective_plot_index=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28353cd43d9b4f6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_fitness_statistics(num_generations, nsga.best_fitness, nsga.worst_fitness, nsga.avg_fitness, title=\"CLIP Score\", multi_objective_plot_index=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "197e58947071ce5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save notebook and components"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23627b477ddc013"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html nsga_notebook.ipynb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c70fcaec676f371"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the run to disk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b79517ef419ec4b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(\"saved_runs\", exist_ok=True)\n",
    "with open(os.path.join(\"saved_runs\", f\"nsga_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(nsga, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31db5e3d88e6b32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the run from disk \n",
    "Notebook and library versions should match with the saved run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc7d188d1100fe4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"saved_runs\", \"insert_filename\"), \"rb\") as f:\n",
    "    run = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "593c3ce4d909254"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fallback functions for when something went wrong"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4550d830b1b47e1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Access Best Solution from Disk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a9063073a48997c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import evolutionary_imaging.processing as ip\n",
    "from PIL import Image\n",
    "\n",
    "num_generations = 4  # Set this to the number of generations you ran (if you didn't finish)\n",
    "generation_dir = os.path.join(\"results\", f\"{num_generations}\")\n",
    "image_files = glob.glob(os.path.join(generation_dir, \"*.png\"))\n",
    "image_files.sort(key=ip.fitness_filename_sorting_key, reverse=True)\n",
    "print(image_files[0])\n",
    "Image.open(image_files[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f775720f03f3e5a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ffmpeg is not installed, create GIF instead"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b003d9c4275cfca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evolutionary_imaging.processing import create_animation_from_generations_pil\n",
    "video_loc = create_animation_from_generations_pil(num_generations)\n",
    "print(video_loc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63df46f328facfc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
