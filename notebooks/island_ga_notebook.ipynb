{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0bdb332e586951",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Template Notebook for using an Island Model GA with Style Evolution on Islands\n",
    "Notebook Version: 0.7.0 (15/03/2025)\n",
    "* include TensorboardEmbedVisualizer\n",
    "* rename functions, conditionally save images\n",
    "* show parent history of solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951256adc75dd6b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "70d5bde37fd9b5d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evolutionary.history import SolutionHistoryKey\n",
    "# Google Colab: Execute this to install packages and setup drive\n",
    "!pip install \"evolutionary[prompt_embedding] @ git+https://git@github.com/malthee/evolutionary-diffusion.git\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b407fd7db4d20e37",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Mount drive to save results\n",
    "from google.colab import drive\n",
    "import evolutionary_imaging.processing as ip\n",
    "import evolutionary_prompt_embedding.tensorboard_embed_visualizer as ev\n",
    "drive.mount(\"/content/drive\")\n",
    "base_path = \"/content/drive/MyDrive/evolutionary/\"\n",
    "ip.RESULTS_FOLDER = base_path + ip.RESULTS_FOLDER\n",
    "ev.DEFAULT_OUTPUT_FOLDER = base_path + \"vis\"\n",
    "save_run_path = base_path + \"saved_runs\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd15039ac09f2d77",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93564491cac9c57d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "bec91dcfcd6297e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evolutionary.plotting import plot_fitness_statistics, plot_time_statistics\n",
    "import evolutionary_imaging.processing as ip\n",
    "import evolutionary_prompt_embedding.tensorboard_embed_visualizer as ev\n",
    "from diffusers.utils import logging\n",
    "from evolutionary_imaging.processing import create_animation_from_generations, create_generation_image_grid, save_images_from_generation\n",
    "import torch\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "176a6b162c07b30b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "logging.disable_progress_bar() # Or else your output will be full of progress bars\n",
    "logging.set_verbosity_error() # Enable again if you are having problems\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To remove warning of libraries using tokenizers\n",
    "# Change the results folder for images and embedding visualization if you want to\n",
    "# ip.RESULTS_FOLDER = \"choose_your_destination\"\n",
    "# ev.DEFAULT_OUTPUT_FOLDER = \"choose_your_destination\"\n",
    "# save_run_path = \"saved_runs\"\n",
    "\n",
    "use_visualizer = True # Set to False if you don't want to use the TensorboardEmbedVisualizer\n",
    "save_images = True # Set to False if you don't want to save images\n",
    "print(torch.random.get_rng_state()) # Check torch random state, used across all libraries. Caution setting fixed seeds as it affects not only generation but also variation."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from evolutionary_prompt_embedding.argument_types import PooledPromptEmbedData\n",
    "from evolutionary_prompt_embedding.image_creation import SDXLPromptEmbeddingImageCreator\n",
    "from evolutionary_prompt_embedding.variation import \\\n",
    "    UniformGaussianMutatorArguments, PooledUniformGaussianMutator, PooledArithmeticCrossover, PooledUniformCrossover\n",
    "from evolutionary_prompt_embedding.value_ranges import SDXLTurboEmbeddingRange, SDXLTurboPooledEmbeddingRange\n",
    "from evolutionary.evolutionary_selectors import TournamentSelector, RouletteWheelSelector, RankSelector\n",
    "from evolutionary.evaluators import CappedEvaluator, GoalDiminishingEvaluator, MultiObjectiveEvaluator\n",
    "from evolutionary.algorithms.island_model import IslandModel\n",
    "from evolutionary.algorithms.ga import GeneticAlgorithm\n",
    "from evolutionary.algorithms.nsga_ii import NSGA_II, NSGATournamentSelector\n",
    "from evolutionary_imaging.evaluators import AIDetectionImageEvaluator, AestheticsImageEvaluator, SingleCLIPIQAEvaluator\n",
    "from evolutionary_prompt_embedding.tensorboard_embed_visualizer import TensorboardEmbedVisualizer, EmbeddingVariant\n",
    "\n",
    "visualizer = TensorboardEmbedVisualizer[PooledPromptEmbedData, [str, str, str, str]]([\"Index\", \"Generation\", \"Fitness\", \"Island\"])\n",
    "\n",
    "class IslandPostEvaluationCallback:\n",
    "    \"\"\"Class to contain post evaluation callbacks for islands; used to allow pickling\"\"\"\n",
    "    def __init__(self, ident: int, description: str):\n",
    "        self.ident = ident\n",
    "        self.description = description\n",
    "\n",
    "    def __call__(self, g, a):\n",
    "        image_paths = None\n",
    "        if save_images:\n",
    "            image_paths = save_images_from_generation(a.population, g, self.ident)\n",
    "        if use_visualizer:\n",
    "            for i, s in enumerate(a.population):\n",
    "                visualizer.add_embedding(s.arguments, [str(i), str(g), f\"{s.fitness:.3f}\", self.description], image_paths[i] if image_paths else None)\n",
    "\n",
    "population_size = 8\n",
    "num_generations = 30\n",
    "batch_size = 1\n",
    "elitism = None\n",
    "inference_steps = 4\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "migration_size = 1\n",
    "migration_interval = 1\n",
    "\n",
    "art_styles = [\n",
    "    \"Prehistoric Art\",  # c. 40,000 BCE - 4,000 BCE\n",
    "#   \"Ancient Egyptian Art\",  # c. 3,100 BCE - 332 BCE\n",
    "    \"Classical Greek Art\",  # c. 480 BCE - 323 BCE\n",
    "#    \"Roman Art\",  # c. 500 BCE - 476 CE\n",
    "#    \"Byzantine Art\",  # c. 330 CE - 1453 CE\n",
    "    \"Islamic Art\",  # c. 7th Century - Present\n",
    "  #  \"Romanesque Art\",  # c. 1000 CE - 1200 CE\n",
    "   # \"Gothic Art\",  # c. 12th Century - 16th Century\n",
    "    \"Renaissance Art\",  # c. 14th Century - 17th Century\n",
    " #   \"Baroque Art\",  # c. 1600 CE - 1750 CE\n",
    " #   \"Neoclassicism\",  # c. 18th Century - Early 19th Century\n",
    "    \"Romanticism\",  # c. Late 18th Century - Mid 19th Century\n",
    "    \"Realism\",  # c. Mid 19th Century\n",
    "    \"Impressionism\",  # c. 1860s - 1880s\n",
    " #   \"Modernism\",  # Late 19th Century - 1970s\n",
    "    \"Contemporary Art\"  # Post-1945 - Present\n",
    "]\n",
    "\n",
    "embedding_range = SDXLTurboEmbeddingRange()\n",
    "pooled_embedding_range = SDXLTurboPooledEmbeddingRange()\n",
    "\n",
    "creator = SDXLPromptEmbeddingImageCreator(batch_size=batch_size, inference_steps=inference_steps)\n",
    "evaluator = AestheticsImageEvaluator() # For diverse results avoid high selection pressure, the AestheticsEvaluator produces average good-looking images at scores 5-6\n",
    "crossover = PooledArithmeticCrossover(interpolation_weight=0.5, interpolation_weight_pooled=0.5)\n",
    "mutation_arguments = UniformGaussianMutatorArguments(mutation_rate=0.05, mutation_strength=1.5, \n",
    "                                                     clamp_range=(embedding_range.minimum, embedding_range.maximum)) \n",
    "mutation_arguments_pooled = UniformGaussianMutatorArguments(mutation_rate=0.05, mutation_strength=0.4, \n",
    "                                                            clamp_range=(pooled_embedding_range.minimum, pooled_embedding_range.maximum))\n",
    "mutator = PooledUniformGaussianMutator(mutation_arguments, mutation_arguments_pooled)\n",
    "selector = RouletteWheelSelector() # Less selection pressure, more exploration\n",
    "\n",
    "ga_instances = []\n",
    "\n",
    "init_crossover = PooledArithmeticCrossover(interpolation_weight=0.8, interpolation_weight_pooled=0.8)\n",
    "for i, style in enumerate(art_styles):\n",
    "    style_arg = creator.arguments_from_prompt(style)\n",
    "    init_args = [init_crossover.crossover(style_arg,  # Combine the style with a random tensor, weighted towards the artist\n",
    "                                          PooledPromptEmbedData(embedding_range.random_tensor_in_range(), pooled_embedding_range.random_tensor_in_range())) \n",
    "                 for _ in range(population_size)]\n",
    "    post_evaluation_callback = IslandPostEvaluationCallback(i, style)\n",
    " \n",
    "    ga_instances.append(GeneticAlgorithm(\n",
    "        population_size=population_size,\n",
    "        num_generations=num_generations,\n",
    "        solution_creator=creator,\n",
    "        evaluator=evaluator,\n",
    "        mutator=mutator,\n",
    "        crossover=crossover,\n",
    "        selector=selector,\n",
    "        initial_arguments=init_args,\n",
    "        crossover_rate=crossover_rate,\n",
    "        mutation_rate=mutation_rate,\n",
    "        elitism_count=elitism,\n",
    "        post_evaluation_callback=post_evaluation_callback,\n",
    "        ident=i\n",
    "    ))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e2256a4cf30a88a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "island_model = IslandModel(\n",
    "    ga_instances,\n",
    "    migration_size=migration_size,\n",
    "    migration_interval=migration_interval,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "935da12fdef0f9e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "best_solutions = island_model.run()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "138e75cca37887ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "# Show best solution\n",
    "for i, best_solution in enumerate(best_solutions):\n",
    "    print(f\"Highest scoring solution for epoch {art_styles[i]}: {best_solution.fitness}\")\n",
    "\n",
    "make_image_grid([image for solution in best_solutions for image in solution.result.images], 2, batch_size * len(best_solutions) // 2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Print the history of a solution",
   "id": "a0ffc73d8085c06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import IFrame, display\n",
    "from evolutionary.history import SolutionHistoryKey, SolutionHistoryItem\n",
    "from evolutionary_imaging.family_tree import visualize_family_tree\n",
    "from PIL import Image\n",
    "\n",
    "history_format = \"png\" # Supports graphviz formats\n",
    "history_key = SolutionHistoryKey(index=0, generation=4, ident=5) # Index, Generation, Ident of Island\n",
    "dot = visualize_family_tree(history=island_model.statistics.solution_history, root_key=history_key, depth=6, format=history_format)\n",
    "history_path = dot.render(filename=\"family_tree\", cleanup=True, format=history_format)\n",
    "Image.open(history_path) # PNG\n",
    "# display(IFrame(\"family_tree.pdf\", width=1000, height=1000)) # PDF\n",
    "#print(island_model.statistics.history_string(key=history_key, depth=3)) # Textual"
   ],
   "id": "5d6c847cc08520aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize Embeddings with the Tensorboard Embedding Projector",
   "id": "e31077f657f82381"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This will save the embeddings and the metadata to your disk\n",
    "visualizer.generate_visualization(\n",
    "    sprite_single_image_dim=(80, 80),\n",
    "    #filter_predicate=lambda e, l, i: int(l[0]) < 3, # Adjust this to filter embeddings if needed\n",
    ")"
   ],
   "id": "af0b1aa6d31c0f7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir={visualizer.output_folder}"
   ],
   "id": "963674b61ba03f08",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24ec401b70d26330",
   "metadata": {
    "collapsed": false
   },
   "source": "## Create a video from the generational progress showing the top images for each island"
  },
  {
   "cell_type": "code",
   "id": "654d29c0a9adc5ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for gen in range(island_model.completed_generations):\n",
    "    create_generation_image_grid(gen, images_per_row=4, max_images=16, label_fontsize=10, ident_mapper=art_styles, group_by_ident=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0bc3e27bc037fc5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "video_loc = create_animation_from_generations(island_model.completed_generations)\n",
    "print(video_loc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e7710ea6363c8fc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot statistics"
   ]
  },
  {
   "cell_type": "code",
   "id": "28353cd43d9b4f6b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "stats = island_model.statistics\n",
    "plot_fitness_statistics(island_model.completed_generations, stats.best_fitness, stats.worst_fitness, stats.avg_fitness)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcc8f01eabfcf056",
   "metadata": {
    "collapsed": false
   },
   "source": "plot_time_statistics(stats.evaluation_time, stats.creation_time, stats.post_evaluation_time)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a0f4fb91ee79569",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save the run to disk"
   ]
  },
  {
   "cell_type": "code",
   "id": "c3e2e39f5fca76da",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "if \"save_run_path\"\"\" not in globals():\n",
    "    save_run_path = \"saved_runs\"\n",
    "os.makedirs(save_run_path, exist_ok=True)\n",
    "output_file = os.path.join(save_run_path, f\"island_model_v0_7_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\")\n",
    "with open(output_file, \"wb\") as f:\n",
    "    pickle.dump(island_model, f)\n",
    "print(f\"Run saved to {output_file}\")\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90e1117acb713a12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the run from disk \n",
    "Notebook and library versions should match with the saved run"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5fd533c22309504",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"saved_runs\", \"insert_filename.pkl\"), \"rb\") as f:\n",
    "    island_model = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4550d830b1b47e1a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Fallback functions for when something went wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9063073a48997c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Access Best Solution from Disk"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f775720f03f3e5a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import evolutionary_imaging.processing as ip\n",
    "from PIL import Image\n",
    "\n",
    "num_generations = island_model.completed_generations  # Set this to the number of generations you ran (if you didn't finish)\n",
    "generation_dir = os.path.join(ip.RESULTS_FOLDER, f\"{num_generations}\")\n",
    "image_files = glob.glob(os.path.join(generation_dir, \"*.png\"))\n",
    "image_files.sort(key=ip.fitness_filename_sorting_key, reverse=True)\n",
    "print(image_files[0])\n",
    "Image.open(image_files[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b003d9c4275cfca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ffmpeg is not installed, create GIF instead"
   ]
  },
  {
   "cell_type": "code",
   "id": "63df46f328facfc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evolutionary_imaging.processing import create_animation_from_generations_pil\n",
    "video_loc = create_animation_from_generations_pil(num_generations)\n",
    "print(video_loc)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
