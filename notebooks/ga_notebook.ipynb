{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0bdb332e586951",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Template Notebook for using Genetic Algorithms exploring the Prompt Embedding space\n",
    "Notebook Version: 0.6.0 (15/03/2025)\n",
    "* include TensorboardEmbedVisualizer\n",
    "* rename functions, conditionally save images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe4679bcd39d1d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "502c2560ba98e504",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Google Colab: Execute this to install packages and setup drive\n",
    "!pip install \"evolutionary[prompt_embedding] @ git+https://git@github.com/malthee/evolutionary-diffusion.git\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15dd267150cff8b1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Mount drive to save results\n",
    "from google.colab import drive\n",
    "import evolutionary_imaging.processing as ip\n",
    "import evolutionary_prompt_embedding.tensorboard_embed_visualizer as ev\n",
    "drive.mount(\"/content/drive\")\n",
    "base_path = \"/content/drive/MyDrive/evolutionary/\"\n",
    "ip.RESULTS_FOLDER = base_path + ip.RESULTS_FOLDER\n",
    "ev.DEFAULT_OUTPUT_FOLDER = base_path + \"vis\"\n",
    "save_run_path = base_path + \"saved_runs\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4453e3a7d102a17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45f787c7040090ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "72e216fd5c2b33c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evolutionary.plotting import plot_fitness_statistics, plot_time_statistics\n",
    "import evolutionary_imaging.processing as ip\n",
    "import evolutionary_prompt_embedding.tensorboard_embed_visualizer as ev\n",
    "from diffusers.utils import logging\n",
    "from evolutionary_imaging.processing import create_animation_from_generations, create_generation_image_grid, save_images_from_generation\n",
    "import torch\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f2adb778c9e1c0f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "logging.disable_progress_bar() # Or else your output will be full of progress bars\n",
    "logging.set_verbosity_error() # Enable again if you are having problems\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To remove warning of libraries using tokenizers\n",
    "# Change the results folder for images and embedding visualization if you want to\n",
    "# ip.RESULTS_FOLDER = \"choose_your_destination\"\n",
    "# ev.DEFAULT_OUTPUT_FOLDER = \"choose_your_destination\"\n",
    "# save_run_path = \"saved_runs\"\n",
    "use_visualizer = True # Set to False if you don't want to use the TensorboardEmbedVisualizer\n",
    "save_images = True # Set to False if you don't want to save images\n",
    "print(torch.random.get_rng_state()) # Check torch random state, used across all libraries. Caution setting fixed seeds as it affects not only generation but also variation."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from evolutionary_prompt_embedding.argument_types import PooledPromptEmbedData\n",
    "from evolutionary_prompt_embedding.image_creation import SDXLPromptEmbeddingImageCreator\n",
    "from evolutionary_prompt_embedding.variation import \\\n",
    "    UniformGaussianMutatorArguments, PooledUniformGaussianMutator, PooledArithmeticCrossover\n",
    "from evolutionary_prompt_embedding.value_ranges import SDXLTurboEmbeddingRange, SDXLTurboPooledEmbeddingRange\n",
    "from evolutionary.evolutionary_selectors import TournamentSelector\n",
    "from evolutionary.algorithms.ga import GeneticAlgorithm\n",
    "from evolutionary_imaging.evaluators import AIDetectionImageEvaluator, AestheticsImageEvaluator, CLIPScoreEvaluator, SingleCLIPIQAEvaluator\n",
    "from evolutionary_prompt_embedding.tensorboard_embed_visualizer import TensorboardEmbedVisualizer, EmbeddingVariant\n",
    "\n",
    "visualizer = TensorboardEmbedVisualizer[PooledPromptEmbedData, [str, str, str]]([\"Index\", \"Generation\", \"Fitness\"])\n",
    "\n",
    "def post_evaluation_callback(g, a):\n",
    "    image_paths = None\n",
    "    if save_images:\n",
    "        save_images_from_generation(a.population, g)\n",
    "        image_paths = save_images_from_generation(a.population, g)\n",
    "    if use_visualizer:\n",
    "        for i, s in enumerate(a.population):\n",
    "            visualizer.add_embedding(s.arguments, [str(i), str(g), f\"{s.fitness:.3f}\"], image_paths[i] if image_paths else None)\n",
    "\n",
    "population_size = 10\n",
    "num_generations = 10\n",
    "batch_size = 1\n",
    "elitism = 1\n",
    "inference_steps = 3\n",
    "crossover_proportion = 0.8\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.2\n",
    "strict_osga = False\n",
    "prompt = None\n",
    "\n",
    "# Define min/max values for the prompt embeddings\n",
    "embedding_range = SDXLTurboEmbeddingRange()\n",
    "pooled_embedding_range = SDXLTurboPooledEmbeddingRange()\n",
    "\n",
    "creator = SDXLPromptEmbeddingImageCreator(batch_size=batch_size, inference_steps=inference_steps)\n",
    "evaluator = AestheticsImageEvaluator()\n",
    "crossover = PooledArithmeticCrossover(interpolation_weight=0.5, interpolation_weight_pooled=0.5, \n",
    "                                      proportion=crossover_proportion, proportion_pooled=crossover_proportion)\n",
    "mutation_arguments = UniformGaussianMutatorArguments(mutation_rate=0.1, mutation_strength=2,\n",
    "                                                     clamp_range=(embedding_range.minimum, embedding_range.maximum)) \n",
    "mutation_arguments_pooled = UniformGaussianMutatorArguments(mutation_rate=0.1, mutation_strength=0.4,\n",
    "                                                            clamp_range=(pooled_embedding_range.minimum, pooled_embedding_range.maximum))\n",
    "mutator = PooledUniformGaussianMutator(mutation_arguments, mutation_arguments_pooled)\n",
    "selector = TournamentSelector(tournament_size=3)\n",
    "\n",
    "# Prepare initial arguments, random population of *reasonable* prompt embeddings\n",
    "init_args = [PooledPromptEmbedData(embedding_range.random_tensor_in_range(), pooled_embedding_range.random_tensor_in_range()) \n",
    "                 for _ in range(population_size)]\n",
    "\n",
    "# Create and run the genetic algorithm\n",
    "ga = GeneticAlgorithm(\n",
    "    population_size=population_size,\n",
    "    num_generations=num_generations,\n",
    "    solution_creator=creator,\n",
    "    evaluator=evaluator,\n",
    "    mutator=mutator,\n",
    "    crossover=crossover,\n",
    "    selector=selector,\n",
    "    initial_arguments=init_args,\n",
    "    elitism_count=elitism,\n",
    "    crossover_rate=crossover_rate,\n",
    "    mutation_rate=mutation_rate,\n",
    "    strict_osga=strict_osga,\n",
    "    post_evaluation_callback=post_evaluation_callback,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "935da12fdef0f9e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "best_solution = ga.run()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "138e75cca37887ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "# Show best solution\n",
    "print(best_solution.fitness)\n",
    "make_image_grid(best_solution.result.images, 1, batch_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize Embeddings with the Tensorboard Embedding Projector",
   "id": "5214168b11b23d75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This will save the embeddings and the metadata to your disk\n",
    "visualizer.generate_visualization(\n",
    "    sprite_single_image_dim=(80, 80),\n",
    "    filter_predicate=lambda e, l, i: int(l[0]) < 30 or float(l[2]) > 8.0, # Adjust this to filter embeddings if needed\n",
    ")"
   ],
   "id": "3c3dc3cfde29dce5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir={visualizer.output_folder}"
   ],
   "id": "84b45318bf3b7d51",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c8d0c18b7e8601e",
   "metadata": {
    "collapsed": false
   },
   "source": "## Compare results to their prompt (only for CLIP-Score, AI-Detection)"
  },
  {
   "cell_type": "code",
   "id": "bb1cec69b3581290",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evolutionary_prompt_embedding.image_creation import SDXLPromptEmbeddingImageCreator\n",
    "creator_compare = SDXLPromptEmbeddingImageCreator(batch_size=4, inference_steps=inference_steps)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d1dfaa9b5edba37",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "args = creator_compare.arguments_from_prompt(prompt)\n",
    "solution = creator_compare.create_solution(args)\n",
    "print(evaluator.evaluate(solution.result))\n",
    "make_image_grid(solution.result.images, 2, 2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24ec401b70d26330",
   "metadata": {
    "collapsed": false
   },
   "source": "## Create a video from the generational progress showing the top images"
  },
  {
   "cell_type": "code",
   "id": "654d29c0a9adc5ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for gen in range(ga.completed_generations):\n",
    "    create_generation_image_grid(gen, max_images=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0bc3e27bc037fc5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "video_loc = create_animation_from_generations(ga.completed_generations)\n",
    "print(video_loc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e7710ea6363c8fc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot statistics"
   ]
  },
  {
   "cell_type": "code",
   "id": "28353cd43d9b4f6b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "stats = ga.statistics\n",
    "plot_fitness_statistics(ga.completed_generations, stats.best_fitness, stats.worst_fitness, stats.avg_fitness)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf597a9d029a8720",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_time_statistics(stats.evaluation_time, stats.creation_time)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2195933152aec9b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save notebook and components"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb6427ad0fe12f61",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "!jupyter nbconvert --to html ga_notebook.ipynb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a0f4fb91ee79569",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save the run to disk"
   ]
  },
  {
   "cell_type": "code",
   "id": "c3e2e39f5fca76da",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "if 'save_run_path' not in locals():\n",
    "    save_run_path = \"saved_runs\"\n",
    "os.makedirs(save_run_path, exist_ok=True)\n",
    "output_file = os.path.join(save_run_path, f\"ga_v0_7_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\")\n",
    "with open(output_file, \"wb\") as f:\n",
    "    pickle.dump(ga, f)\n",
    "print(f\"Run saved to {output_file}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae1af9f5da2e8b32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the run from disk \n",
    "Notebook and library versions should match with the saved run"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe9508f9e0c33fef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"saved_runs\", \"insert_filename\"), \"rb\") as f:\n",
    "    run = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4550d830b1b47e1a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Fallback functions for when something went wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9063073a48997c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Access Best Solution from Disk"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f775720f03f3e5a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import evolutionary_imaging.processing as ip\n",
    "from PIL import Image\n",
    "\n",
    "num_generations = ga.completed_generations # Set this to the number of generations you ran (if you didn't finish)\n",
    "generation_dir = os.path.join(ip.RESULTS_FOLDER, f\"{num_generations}\")\n",
    "image_files = glob.glob(os.path.join(generation_dir, \"*.png\"))\n",
    "image_files.sort(key=ip.fitness_filename_sorting_key, reverse=True)\n",
    "print(image_files[0])\n",
    "Image.open(image_files[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b003d9c4275cfca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ffmpeg is not installed, create GIF instead"
   ]
  },
  {
   "cell_type": "code",
   "id": "63df46f328facfc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evolutionary_imaging.processing import create_animation_from_generations_pil\n",
    "video_loc = create_animation_from_generations_pil(num_generations)\n",
    "print(video_loc)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
