{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Template Notebook for testing Genetic Algorithms exploring the prompt embedding latent space\n",
    "Notebook Version: 0.3 (01/03/2024)\n",
    "* added Colab compatibility"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c0bdb332e586951"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Google Colab Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bafe4679bcd39d1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Google Colab: Execute this to install packages and setup drive\n",
    "!pip install \"evolutionary[all] @ git+https://git@github.com/malthee/evolutionary-diffusion.git\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "502c2560ba98e504"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mount drive to save resutls\n",
    "from google.colab import drive\n",
    "from evolutionary_imaging.processing import RESULTS_FOLDER\n",
    "drive.mount('/content/drive')\n",
    "base_path = \"/content/drive/MyDrive/evolutionary\"\n",
    "RESULTS_FOLDER = base_path + RESULTS_FOLDER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15dd267150cff8b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45f787c7040090ec"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/msalv/dev/evolutionary-diffusion/venv/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from evolutionary.plotting import plot_fitness_statistics\n",
    "from evolutionary_imaging.processing import RESULTS_FOLDER\n",
    "from diffusers.utils import logging\n",
    "from evolutionary_imaging.processing import create_animation_from_generations, create_generation_image_grid, save_images_from_generation\n",
    "import torch\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T10:17:24.214748Z",
     "start_time": "2024-03-06T10:17:22.899969Z"
    }
   },
   "id": "72e216fd5c2b33c9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 73, 101, 254,  ...,   0,   0,   0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "logging.disable_progress_bar() # Or else your output will be full of progress bars\n",
    "logging.set_verbosity_error() # Enable again if you are having problems\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To remove warning of libraries using tokenizers\n",
    "# Change the results folder for images if you want to \n",
    "# RESULTS_FOLDER = 'choose_your_destination'\n",
    "\n",
    "def save_images_post_evaluation(g, a):\n",
    "    save_images_from_generation(a.population, g)\n",
    "    \n",
    "# Check torch random state, used across all libraries. Caution setting fixed seeds as it affects not only generation but also variation.\n",
    "print(torch.random.get_rng_state())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T10:17:26.739530Z",
     "start_time": "2024-03-06T10:17:26.731979Z"
    }
   },
   "id": "2f2adb778c9e1c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-06T10:18:33.932380Z",
     "start_time": "2024-03-06T10:18:08.857408Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/msalv/dev/evolutionary-diffusion/venv/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded StableDiffusionXLPipeline {\n",
      "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
      "  \"_diffusers_version\": \"0.26.3\",\n",
      "  \"_name_or_path\": \"stabilityai/sdxl-turbo\",\n",
      "  \"feature_extractor\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"force_zeros_for_empty_prompt\": true,\n",
      "  \"image_encoder\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"scheduler\": [\n",
      "    \"diffusers\",\n",
      "    \"EulerAncestralDiscreteScheduler\"\n",
      "  ],\n",
      "  \"text_encoder\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModel\"\n",
      "  ],\n",
      "  \"text_encoder_2\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModelWithProjection\"\n",
      "  ],\n",
      "  \"tokenizer\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"tokenizer_2\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"unet\": [\n",
      "    \"diffusers\",\n",
      "    \"UNet2DConditionModel\"\n",
      "  ],\n",
      "  \"vae\": [\n",
      "    \"diffusers\",\n",
      "    \"AutoencoderKL\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from evolutionary_prompt_embedding.argument_types import PooledPromptEmbedData\n",
    "from evolutionary_prompt_embedding.image_creation import SDXLPromptEmbeddingImageCreator\n",
    "from evolutionary_prompt_embedding.variation import \\\n",
    "    UniformGaussianMutatorArguments, PooledUniformGaussianMutator, PooledArithmeticCrossover\n",
    "from evolutionary_prompt_embedding.value_ranges import SDXLTurboEmbeddingRange, SDXLTurboPooledEmbeddingRange\n",
    "from evolutionary.evolutionary_selectors import TournamentSelector\n",
    "from evolutionary.algorithms.ga import GeneticAlgorithm\n",
    "from evolutionary_imaging.evaluators import AIDetectionImageEvaluator, AestheticsImageEvaluator, CLIPScoreEvaluator, SingleCLIPIQAEvaluator\n",
    "\n",
    "population_size = 4\n",
    "num_generations = 4\n",
    "batch_size = 1\n",
    "elitism = 1\n",
    "inference_steps = 1\n",
    "prompt = \"aesthetic\"\n",
    "\n",
    "# Define min/max values for the prompt embeddings\n",
    "embedding_range = SDXLTurboEmbeddingRange()\n",
    "pooled_embedding_range = SDXLTurboPooledEmbeddingRange()\n",
    "# Create the necessary components for the genetic algorithm\n",
    "creator = SDXLPromptEmbeddingImageCreator(batch_size=batch_size, inference_steps=inference_steps)\n",
    "evaluator = SingleCLIPIQAEvaluator(metric=(\"happy\", \"sad\"))\n",
    "crossover = PooledArithmeticCrossover(crossover_rate=0.5, crossover_rate_pooled=0.5)\n",
    "mutation_arguments = UniformGaussianMutatorArguments(mutation_rate=0.05, mutation_strength=3, \n",
    "                                                     clamp_range=(embedding_range.minimum, embedding_range.maximum)) \n",
    "mutation_arguments_pooled = UniformGaussianMutatorArguments(mutation_rate=0.05, mutation_strength=0.7, \n",
    "                                                            clamp_range=(pooled_embedding_range.minimum, pooled_embedding_range.maximum))\n",
    "mutator = PooledUniformGaussianMutator(mutation_arguments, mutation_arguments_pooled)\n",
    "selector = TournamentSelector(tournament_size=3)\n",
    "\n",
    "# Prepare initial arguments, random population of *reasonable* prompt embeddings\n",
    "init_args = [PooledPromptEmbedData(embedding_range.random_tensor_in_range(), pooled_embedding_range.random_tensor_in_range()) \n",
    "             for _ in range(population_size)]\n",
    "\n",
    "# Create and run the genetic algorithm\n",
    "ga = GeneticAlgorithm(\n",
    "    population_size=population_size,\n",
    "    num_generations=num_generations,\n",
    "    solution_creator=creator,\n",
    "    evaluator=evaluator,\n",
    "    mutator=mutator,\n",
    "    crossover=crossover,\n",
    "    selector=selector,\n",
    "    initial_arguments=init_args,\n",
    "    elitism_count=elitism,\n",
    "    post_evaluation_callback=save_images_post_evaluation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.42s/generation]\n"
     ]
    }
   ],
   "source": [
    "best_solution = ga.run()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T10:21:07.663878Z",
     "start_time": "2024-03-06T10:20:51.858460Z"
    }
   },
   "id": "935da12fdef0f9e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "# Show best solution\n",
    "print(best_solution.fitness)\n",
    "make_image_grid(best_solution.result.images, 1, batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "138e75cca37887ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare to directly generating it with the prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c8d0c18b7e8601e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evolutionary_prompt_embedding.image_creation import SDXLPromptEmbeddingImageCreator\n",
    "creator_compare = SDXLPromptEmbeddingImageCreator(batch_size=10, inference_steps=inference_steps)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb1cec69b3581290"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "args = creator_compare.arguments_from_prompt(prompt)\n",
    "solution = creator_compare.create_solution(args)\n",
    "print(evaluator.evaluate(solution.result))\n",
    "make_image_grid(solution.result.images, 2, 5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d1dfaa9b5edba37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the evolution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ec401b70d26330"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gen in range(num_generations):\n",
    "    create_generation_image_grid(gen, max_images=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "654d29c0a9adc5ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "video_loc = create_animation_from_generations(num_generations)\n",
    "print(video_loc)\n",
    "from IPython.display import Video\n",
    "Video(filename=video_loc) # This does not work for all browsers/notebooks, set embed to true when you want to include it in the notebook (warning large file size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bc3e27bc037fc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot fitness statistics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7710ea6363c8fc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_fitness_statistics(num_generations, ga.best_fitness, ga.worst_fitness, ga.avg_fitness)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28353cd43d9b4f6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save notebook and components"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2195933152aec9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html ga_notebook.ipynb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb6427ad0fe12f61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the run to disk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a0f4fb91ee79569"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(\"saved_runs\", exist_ok=True)\n",
    "with open(os.path.join(\"saved_runs\", f\"ga_clipscore{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(ga, f) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e2e39f5fca76da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the run from disk \n",
    "Notebook and library versions should match with the saved run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae1af9f5da2e8b32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"saved_runs\", \"insert_filename\"), \"rb\") as f:\n",
    "    run = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe9508f9e0c33fef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fallback functions for when something went wrong"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4550d830b1b47e1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Access Best Solution from Disk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a9063073a48997c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import evolutionary_imaging.processing as ip\n",
    "from PIL import Image\n",
    "\n",
    "num_generations = 42  # Set this to the number of generations you ran (if you didn't finish)\n",
    "generation_dir = os.path.join(ip.RESULTS_FOLDER, f\"{num_generations}\")\n",
    "image_files = glob.glob(os.path.join(generation_dir, \"*.png\"))\n",
    "image_files.sort(key=ip.fitness_filename_sorting_key, reverse=True)\n",
    "print(image_files[0])\n",
    "Image.open(image_files[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f775720f03f3e5a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ffmpeg is not installed, create GIF instead"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b003d9c4275cfca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evolutionary_imaging.processing import create_animation_from_generations_pil\n",
    "video_loc = create_animation_from_generations_pil(num_generations)\n",
    "print(video_loc)\n",
    "from IPython.display import Video\n",
    "Video(filename=video_loc) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63df46f328facfc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
