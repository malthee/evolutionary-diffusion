{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SDXL-Turbo: Finding a reasonable CLAMP range for exploring the prompt embedding space\n",
    "Using the diverse parti prompts v2 (1,6k entries) to explore the range of values for prompt embeddings. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7889ddecfcb57765"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from evolutionary_prompt_embedding.image_creation import SDPromptEmbeddingImageCreator\n",
    "from evolutionary_prompt_embedding.utils import clamp_range_from_parti, clamp_range_per_entry"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:50:36.349633Z",
     "start_time": "2024-02-26T12:50:34.469151Z"
    }
   },
   "id": "c18d4cb96ff196ec"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54fbda84c30f476981b840f90fe83535"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded StableDiffusionPipeline {\n",
      "  \"_class_name\": \"StableDiffusionPipeline\",\n",
      "  \"_diffusers_version\": \"0.25.0\",\n",
      "  \"_name_or_path\": \"stabilityai/sd-turbo\",\n",
      "  \"feature_extractor\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"image_encoder\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"requires_safety_checker\": false,\n",
      "  \"safety_checker\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"scheduler\": [\n",
      "    \"diffusers\",\n",
      "    \"EulerDiscreteScheduler\"\n",
      "  ],\n",
      "  \"text_encoder\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModel\"\n",
      "  ],\n",
      "  \"tokenizer\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"unet\": [\n",
      "    \"diffusers\",\n",
      "    \"UNet2DConditionModel\"\n",
      "  ],\n",
      "  \"vae\": [\n",
      "    \"diffusers\",\n",
      "    \"AutoencoderKL\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "creator = SDPromptEmbeddingImageCreator(batch_size=1, inference_steps=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:50:47.339120Z",
     "start_time": "2024-02-26T12:50:36.603217Z"
    }
   },
   "id": "bd6a00facc2aa847"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple min-max range for prompt_embeds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0bbee7a3546cb98"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:51:31.757434Z",
     "start_time": "2024-02-26T12:50:47.337164Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (84 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "Range for prompt_embeds:  (-10.234375, 15.6484375)\n"
     ]
    }
   ],
   "source": [
    "test1 = clamp_range_from_parti(creator, lambda_accessor=lambda x: x.prompt_embeds)\n",
    "print(\"Range for prompt_embeds: \", test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the SD-Turbo model the CLAMP range for prompt_embeds is around (-10.2, 15.6).\n",
    "Keep in mind you can extend the values, but this restricts the search space to a reasonable range."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7be8abc13dabcfcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More detailed CLAMP range for each entry in the tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b465749ccf0db9a1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "prompt_embeds:\n",
      "Min tensor:  tensor([[[-0.3132, -0.4475, -0.0082,  ...,  0.2544, -0.0325, -0.2959],\n",
      "         [-2.4746, -2.2949, -3.8438,  ..., -1.5371, -3.7773, -2.3926],\n",
      "         [-3.6895, -3.8496, -3.6426,  ..., -2.2070, -3.2363, -4.2031],\n",
      "         ...,\n",
      "         [-0.9478, -2.6660, -1.1367,  ..., -1.1592, -1.2041, -1.0410],\n",
      "         [-1.0312, -2.6875, -1.0918,  ..., -1.3984, -1.3584, -0.6152],\n",
      "         [-1.1230, -3.0918, -3.0703,  ..., -1.6553, -1.5303, -0.3486]]],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "Max tensor:  tensor([[[-0.3132, -0.4475, -0.0082,  ...,  0.2544, -0.0325, -0.2959],\n",
      "         [ 3.3125,  1.7324,  1.9639,  ...,  2.4590,  2.7031,  2.3008],\n",
      "         [ 2.9746,  2.4570,  2.4492,  ...,  3.1328,  3.8105,  2.9688],\n",
      "         ...,\n",
      "         [ 2.3242,  0.4470,  0.9487,  ...,  0.5933,  1.2305,  1.3486],\n",
      "         [ 2.2305,  0.9614,  1.0029,  ...,  0.5439,  1.1201,  1.4141],\n",
      "         [ 2.0137,  0.5552,  0.6274,  ...,  1.1982,  2.0859,  2.7773]]],\n",
      "       device='mps:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "min_tensor, max_tensor = clamp_range_per_entry(creator, lambda_accessor=lambda x: x.prompt_embeds)\n",
    "print(\"prompt_embeds:\")\n",
    "print(\"Min tensor: \", min_tensor)\n",
    "print(\"Max tensor: \", max_tensor)\n",
    "torch.save(min_tensor.to('cpu'), 'sd_turbo_min_tensor.pt')\n",
    "torch.save(max_tensor.to('cpu'), 'sd_turbo_max_tensor.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:52:14.745554Z",
     "start_time": "2024-02-26T12:51:31.756489Z"
    }
   },
   "id": "309f9b657f26c58"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value range:  tensor(332369., device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "diff_tensor = (max_tensor - min_tensor).to(dtype=torch.float32)\n",
    "print(\"Value range: \", diff_tensor.sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T18:23:10.004070Z",
     "start_time": "2024-02-26T18:23:09.388600Z"
    }
   },
   "id": "5ae33272b2b028da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2b19fdd82475ce3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
