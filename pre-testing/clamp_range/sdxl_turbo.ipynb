{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SDXL-Turbo: Finding a reasonable CLAMP range for exploring the prompt embedding space\n",
    "Using the diverse parti prompts v2 (1,6k entries) to explore the range of values for prompt embeddings. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7889ddecfcb57765"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "from evolutionary_prompt_embedding.image_creation import SDXLPromptEmbeddingImageCreator\n",
    "from evolutionary_prompt_embedding.utils import clamp_range_from_parti, clamp_range_per_entry"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T19:06:52.751601Z",
     "start_time": "2024-02-25T19:06:52.748475Z"
    }
   },
   "id": "c18d4cb96ff196ec"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'safety_checker': None, 'requires_safety_checker': False} are not expected by StableDiffusionXLPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23804dcf9a344bf49eb7a7c712b755c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded StableDiffusionXLPipeline {\n",
      "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
      "  \"_diffusers_version\": \"0.25.0\",\n",
      "  \"_name_or_path\": \"stabilityai/sdxl-turbo\",\n",
      "  \"feature_extractor\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"force_zeros_for_empty_prompt\": true,\n",
      "  \"image_encoder\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"scheduler\": [\n",
      "    \"diffusers\",\n",
      "    \"EulerAncestralDiscreteScheduler\"\n",
      "  ],\n",
      "  \"text_encoder\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModel\"\n",
      "  ],\n",
      "  \"text_encoder_2\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModelWithProjection\"\n",
      "  ],\n",
      "  \"tokenizer\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"tokenizer_2\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"unet\": [\n",
      "    \"diffusers\",\n",
      "    \"UNet2DConditionModel\"\n",
      "  ],\n",
      "  \"vae\": [\n",
      "    \"diffusers\",\n",
      "    \"AutoencoderKL\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "creator = SDXLPromptEmbeddingImageCreator(batch_size=1, inference_steps=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T18:45:19.188875Z",
     "start_time": "2024-02-25T18:44:56.606182Z"
    }
   },
   "id": "bd6a00facc2aa847"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple min-max range for prompt_embeds and pooled_prompt_embeds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0bbee7a3546cb98"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T18:48:08.322382Z",
     "start_time": "2024-02-25T18:45:19.186657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (84 > 77). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (84 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "Range for prompt_embeds:  (-809.0, 854.5)\n",
      "Range for pooled_prompt_embeds:  (-8.0625, 7.8828125)\n"
     ]
    }
   ],
   "source": [
    "test1 = clamp_range_from_parti(creator, lambda_accessor=lambda x: x.prompt_embeds)\n",
    "test2 = clamp_range_from_parti(creator, lambda_accessor=lambda x: x.pooled_prompt_embeds)\n",
    "print(\"Range for prompt_embeds: \", test1)\n",
    "print(\"Range for pooled_prompt_embeds: \", test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the SDXL-Turbo model the CLAMP range for prompt_embeds is around (-810, 860) and for pooled_prompt_embeds it is around (-8, 8).\n",
    "Keep in mind you can extend the values, but this restricts the search space to a reasonable range."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7be8abc13dabcfcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More detailed CLAMP range for each entry in the tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b465749ccf0db9a1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "prompt_embeds:\n",
      "Min tensor:  tensor([[[-3.8926, -2.5117,  4.7148,  ...,  0.1899,  0.4180, -0.2959],\n",
      "         [-1.6904, -1.4238, -1.5117,  ..., -1.5742, -1.9365, -1.4561],\n",
      "         [-1.8291, -1.6348, -1.6777,  ..., -1.8506, -1.7236, -1.9873],\n",
      "         ...,\n",
      "         [-1.4150, -1.3574, -2.2207,  ..., -0.8662, -0.4707, -0.2817],\n",
      "         [-1.4033, -1.3652, -2.2090,  ..., -0.9355, -0.5312, -0.3933],\n",
      "         [-1.3906, -1.2686, -2.1445,  ..., -0.8530, -0.6299, -0.6133]]],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "Max tensor:  tensor([[[-3.8926, -2.5117,  4.7148,  ...,  0.1899,  0.4180, -0.2959],\n",
      "         [ 1.5918,  1.7695,  1.2334,  ...,  1.8398,  2.2480,  1.3789],\n",
      "         [ 1.9492,  1.7354,  1.7012,  ...,  2.1406,  2.3066,  1.7012],\n",
      "         ...,\n",
      "         [ 1.8721,  1.9980,  1.4238,  ...,  0.8379,  0.8945,  0.8320],\n",
      "         [ 1.8477,  2.0039,  1.4102,  ...,  0.7393,  0.7285,  0.7373],\n",
      "         [ 1.8760,  2.0664,  1.3994,  ...,  0.7383,  0.7646,  0.7402]]],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['as a beacon over rolling blue hills']\n",
      "pooled_prompt_embeds:\n",
      "Min tensor pooled:  tensor([[-1.9883, -1.7617, -3.3789,  ..., -3.5781, -5.2734, -2.2422]],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "Max tensor pooled:  tensor([[2.8086, 3.1016, 2.1406,  ..., 1.6865, 3.2480, 2.4883]],\n",
      "       device='mps:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "min_tensor, max_tensor = clamp_range_per_entry(creator, lambda_accessor=lambda x: x.prompt_embeds)\n",
    "print(\"prompt_embeds:\")\n",
    "print(\"Min tensor: \", min_tensor)\n",
    "print(\"Max tensor: \", max_tensor)\n",
    "torch.save(min_tensor.to('cpu'), 'sdxl_turbo_min_tensor.pt')\n",
    "torch.save(max_tensor.to('cpu'), 'sdxl_turbo_max_tensor.pt')\n",
    "min_tensor_pooled, max_tensor_pooled = clamp_range_per_entry(creator, lambda_accessor=lambda x: x.pooled_prompt_embeds)\n",
    "print(\"pooled_prompt_embeds:\")\n",
    "print(\"Min tensor pooled: \", min_tensor_pooled)\n",
    "print(\"Max tensor pooled: \", max_tensor_pooled)\n",
    "torch.save(min_tensor_pooled.to('cpu'), 'sdxl_turbo_min_tensor_pooled.pt')\n",
    "torch.save(max_tensor_pooled.to('cpu'), 'sdxl_turbo_max_tensor_pooled.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T19:36:40.191217Z",
     "start_time": "2024-02-25T19:33:53.230385Z"
    }
   },
   "id": "309f9b657f26c58"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value range:  tensor(542178.6250, device='mps:0')\n",
      "Value range pooled:  tensor(7362.3359, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "diff_tensor = (max_tensor - min_tensor).to(dtype=torch.float32)\n",
    "print(\"Value range: \", diff_tensor.sum())\n",
    "diff_tensor_pooled = (max_tensor_pooled - min_tensor_pooled).to(dtype=torch.float32)\n",
    "print(\"Value range pooled: \", diff_tensor_pooled.sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T19:36:40.198120Z",
     "start_time": "2024-02-25T19:36:40.190755Z"
    }
   },
   "id": "5ae33272b2b028da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f63f9c8018610d58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
